<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en"><head>
    <!-- Global site tag (gtag.js) - Google Analytics -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=UA-122759872-1"></script>
    <script>
        window.dataLayer = window.dataLayer || [];
        function gtag(){dataLayer.push(arguments);}
        gtag('js', new Date());
        
        gtag('config', 'UA-122759872-1');
        </script>
    
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
        <link rel="shortcut icon" HREF="index/favicon.ico">
            <title>Pinxin Liu</title>
            <link rel="stylesheet" type="text/css" href="./index/main.css">
                <link href="./index/css" rel="stylesheet">
                    <style>
                        .quote{
                            font-family: 'Dawning of a New Day';
                            font-weight:bold;
                            font-size:30px;
                        }
                    </style>
                     
</head>

<body>
    <div id="main">
        
        <div class="name">
            Andy (Pinxin) Liu
        </div>
        
        <div>
            <!-- Create a flex container for side-by-side layout -->
            <div style="display: flex; align-items: flex-start; gap: 20px; margin: 20px auto; width: 1000px;">
                <!-- Slideshow container -->
                <div class="slideshow-container" style="width: 256px; margin: 0;">
                    <div class="slide fade">
                        <img src="./index/avatar-1.png" style="width:100%; height:100%; object-fit:contain;">
                    </div>
                    <div class="slide fade">
                        <img src="./index/avatar-2.png" style="width:100%; height:100%; object-fit:contain;">
                    </div>
                    <div class="slide fade">
                        <img src="./index/avatar-3.png" style="width:100%; height:100%; object-fit:contain;">
                    </div>
                    <div class="slide fade">
                        <img src="./index/avatar-4.png" style="width:100%; height:100%; object-fit:contain;">
                    </div>
                    <div class="slide fade">
                        <img src="./index/avatar-5.png" style="width:100%; height:100%; object-fit:contain;">
                    </div>
                    <div class="slide fade">
                        <img src="./index/avatar-6.png" style="width:100%; height:100%; object-fit:contain;">
                    </div>
                    <div class="slide fade">
                        <img src="./index/avatar-7.png" style="width:100%; height:100%; object-fit:contain;">
                    </div>
                    <div class="slide fade">
                        <img src="./index/avatar-8.png" style="width:100%; height:100%; object-fit:contain;">
                    </div>
                </div>

                <!-- Bio content -->
                <div class="bio_format" style="flex: 1; max-width: 700px;">
                    <p> Hi!
                    </p>
                    
                    <p> 
                        I am a PhD student, 
                        supervised by Dr. <a href="https://www.cs.rochester.edu/~cxu22/">Chenliang Xu</a>, 
                        in <a href="https://www.cs.rochester.edu/">Computer Science</a> department at <a href="https://rochester.edu/">University of Rochester</a>.
                        My research interests are Multi-modal Learning and Computer Graphics, including Multi-modal Large Language Models, Digital Human Rendering/Motion Synthesis, and Video Generation.

                        Previously, I was an undergraduate student who received the highest honor distinction in research Bachelor of Science in Computer Science at the University of Rochester.
                    </p>

                    Here is my &nbsp;
                    <a href="mailto:pliu23@u.rochester.edu"><img src="index/gmail_logo.png" width="25px"></a>&nbsp;
                    <a href="https://github.com/andypinxinliu" target="blank"><img src="index/github_logo.png" width="25px"></a>&nbsp;
                    <a href="https://scholar.google.com/citations?user=ZJQldrQAAAAJ&hl=en" target="blank"><img src="index/google_scholar_logo.png" width="25px"></a>&nbsp;
                </div>
            </div>

            <style>
                .slideshow-container {
                    position: relative;
                    width: 256px;
                    height: 256px;
                    background-color: #f5f5f5;
                    border-radius: 8px;
                    overflow: hidden;
                    flex-shrink: 0; /* Prevent container from shrinking */
                }
                .slide {
                    display: none;
                    position: absolute;
                    top: 0;
                    left: 0;
                    width: 100%;
                    height: 100%;
                    display: flex;
                    align-items: center;
                    justify-content: center;
                }
                .slide img {
                    max-width: 100%;
                    max-height: 100%;
                    width: auto;
                    height: auto;
                    object-fit: contain;
                }
                .fade {
                    animation-name: fade;
                    animation-duration: 1.5s;
                }
                @keyframes fade {
                    from {opacity: .4} 
                    to {opacity: 1}
                }
            </style>

            <script>
                let currentSlide = 0;
                const slides = document.getElementsByClassName("slide");
                
                function showSlides() {
                    // Hide all slides
                    for (let i = 0; i < slides.length; i++) {
                        slides[i].style.display = "none";
                    }
                    
                    // Show current slide
                    currentSlide++;
                    if (currentSlide > slides.length) {currentSlide = 1}
                    slides[currentSlide-1].style.display = "block";
                    
                    // Change slide every 5 seconds
                    setTimeout(showSlides, 5000);
                }
                
                // Start the slideshow
                showSlides();
            </script>
        </div>
        
        
        <div>
            <span class="category">NEWS</span>
            <hr class="line">
            <div align=left
                style='
                border: solid 2px grey;
                width: 1000px;
                height: 150px;
                overflow: scroll;
                scrollbar-face-color: #889B9F;
                scrollbar-shadow-color: #3D5054;
                scrollbar-highlight-color: #C3D6DA;
                scrollbar-3dlight-color: #3D5054;
                scrollbar-darkshadow-color: #85989C;
                scrollbar-track-color: #95A6AA;
                scrollbar-arrow-color: #FFD6DA;
                '>
                
                <ul class="item_content">
                    <li>
                        <font color="black"><span>[03/2025] I will join <b>Meta Reality Lab</b> as a <b>Research Scientist Intern</b>.</span></font>
                    </li>
                    <li>
                        <font color="black"><span>[11/2024] One first author paper accepted <b>3DV 2025</b>.</span></font>
                    </li>
                    <li>
                        <font color="black"><span>[09/2024] One co-author paper accepted <b>Siggraph Asia 2024</b>.</span></font>
                    </li>
                    <li>
                        <font color="black"><span>[07/2024] One first author paper accepted <b>ECCV 2024</b>.</span></font>
                    </li>
                    <li>
                        <font color="black"><span>[06/2024] Joined <b>FlawlessAI</b> as a <b>Research Scientist Intern</b>.</span></font>
                    </li>
                    <li>
                        <font color="black"><span>[05/2024] I received a BS degree in Computer Science with the <b>Highest Honor Distinction</b> in Research.
                    </li>
                    
                     <li>
                        <font color="black"><span>[05/2024] One co-authored paper accepted to <b>Interspeech 2024</b>.</span></font>
                    </li>
                     <li>
                        <font color="black"><span>[05/2024] One first-authored paper accepted to <b>ACL 2024</b>.</span></font>
                    </li>
                    <li>
                        <font color="black"><span>[04/2024] I was honored as the National Student Employee of the Year for 2024, selected from a highly competitive pool of six candidates across the country.
                    </li>
                    <li>
                        <font color="black"><span>[12/2023] One first-authored paper accepted to <b>ICASSP 2024</b>.</span></font>
                    </li>
                    <li>
                        <font color="black"><span>[01/2023] One co-authored paper accepted to <b>AAAI 2021 Workshop</b>.</span></font>
                    </li>
                </ul>

            </div>
        </div>
       

        <div>
            <span class="category">PAPERS</span>
            <hr class="line">
            <ol style="padding:0px;list-style-type:none">

                <li class="item_format" style="position:relative">
                    
                    <img src="./research/contextural-gesture-teaser.png" class="img_format">
                        <div class="title_format">
                            <b>Contextual Gesture: Co-Speech Gesture Video Generation through Context-aware Gesture Representation</b>
                            <span class="author_format"><b style="color: #800000">Pinxin Liu</b>, Pengfei Zhang, Hyeongwoo Kim, Pablo Garrido, Ari Sharpio and Kyle Olszewski.</span>
                            <span class="venue_format"><em style="color: #008B8B">Arxiv 2025</em></span>
                            <div class="link_format">
                                [<a href="https://arxiv.org/abs/2502.07239">Paper</a>]
                                [<a href="https://andypinxinliu.github.io/Contextual-Gesture/">Project</a>]
                                [<a href="https://andypinxinliu.github.io/Contextual-Gesture/">Code</a>]
                            </div>
                        </div>
                        <div style="clear:both;"></div>
                        
                </li>

                <li class="item_format" style="position:relative">
                    
                    <img src="./research/gesturelsm-teaser.jpg" class="img_format">
                        <div class="title_format">
                            <b>GestureLSM: Latent Shortcut based Co-Speech Gesture Generation with Spatial-Temporal Modeling</b>
                            <span class="author_format"><b style="color: #800000">Pinxin Liu</b>, Luchuan Song, Junhua Huang, Haiyang Liu and Chenliang Xu.</span>
                            <span class="venue_format"><em style="color: #008B8B">Arxiv 2025</em></span>
                            <div class="link_format">
                                [<a href="https://arxiv.org/abs/2501.18898">Paper</a>]
                                [<a href="https://andypinxinliu.github.io/GestureLSM/">Project</a>]
                                [<a href="https://github.com/andypinxinliu/GestureLSM">Code</a>]
                            </div>
                        </div>
                        <div style="clear:both;"></div>
                        
                </li>


                <li class="item_format" style="position:relative">
                    
                    <img src="./research/kinmo_teaser.png" class="img_format">
                        <div class="title_format">
                            <b>KinMo: Kinematic-aware Human Motion Understanding and Generation</b>
                            <span class="author_format"><b style="color: #800000">Pinxin Liu*</b>, Pengfei Zhang*, Hyeongwoo Kim, Pablo Garrido and Bindita Chaudhuri.</span>
                            <span class="venue_format"><em style="color: #008B8B">Arxiv 2025</em></span>
                            <div class="link_format">
                                [<a href="https://arxiv.org/abs/2411.15472v1">Paper</a>]
                                [<a href="https://andypinxinliu.github.io/KinMo/">Project</a>]
                                [<a href="https://andypinxinliu.github.io/KinMo/">Code</a>]
                            </div>
                        </div>
                        <div style="clear:both;"></div>
                        
                </li>

                <li class="item_format" style="position:relative">
                    
                    <img src="./research/3dv-teaser.jpg" class="img_format">
                        <div class="title_format">
                            <b>GaussianStyle: Gaussian Head Avatar via StyleGAN</b>
                            <span class="author_format"><b style="color: #800000">Pinxin Liu</b>, Luchuan Song, Daoan Zhang, Hang Hua, Yunlong Tang, Huaijin Tu, Jiebo Luo and Chenliang Xu.</span>
                            <span class="venue_format"><em style="color: #008B8B">3DV 2025</em></span>
                            <div class="link_format">
                                <!-- [<a class="btn btn-default abstract" abstract="In this paper, we propose the Efficient Monotonic Video Style Avatar(Emo-Avatar) through deferred neural rendering that enhances.">Abstract</a>] -->
                                [<a href="https://arxiv.org/abs/2402.00827">Paper</a>]
                                [<a href="https://andypinxinliu.github.io/GaussianStyle/">Project</a>]
                                [<a href="https://github.com/andypinxinliu/HumanFaceProject/tree/main/assets/GaussianStyle">Code</a>]
                            </div>
                        </div>
                        <div style="clear:both;"></div>
                        
                </li>

                
                <li class="item_format" style="position:relative">
                    <!-- <img src="./research/depth_estimation.png" class="img_format" style="width:550px;height:300px;"> -->
                    <img src="./research/TextToon-teaser.jpg" class="img_format">
                        <div class="title_format">
                            <b>Texttoon: Real-time text toonify head avatar from single video
                            </b>
                            <span class="author_format">Luchuan Song, Lele Chen, Celong Liu, <b style="color: #800000">Pinxin Liu</b>, and Chenliang Xu.</span>
                            <span class="venue_format"><em style="color: #008B8B">Siggraph Asia 2024</em></span>
                            <div class="link_format">
                                [<a href="https://arxiv.org/abs/2401.09386">Paper</a>]
                                [<a href="https://github.com/Songluchuan/Tri2plane">Project</a>]
                                [<a href="https://github.com/Songluchuan/Tri2plane">Code</a>]
                                [<a href="https://github.com/Songluchuan/Tri2plane">Demo</a>]
                            </div>
                        </div>
                        <div style="clear:both;"></div>
                </li>
                

                        
                <li class="item_format" style="position:relative">
                    <!-- <img src="./research/depth_estimation.png" class="img_format" style="width:550px;height:300px;"> -->
                    <img src="./research/tri-plane_teaser.jpeg" class="img_format">
                        <div class="title_format">
                            <b>Tri^{2}-plane: Thinking Head Avatar via Feature Pyramid
                            </b>
                            <span class="author_format">Luchuan Song, <b style="color: #800000">Pinxin Liu</b>, Lele Chen, Celong Liu and Chenliang Xu.</span>
                            <span class="venue_format"><em style="color: #008B8B">ECCV 2024</em></span>
                            <div class="link_format">
                                [<a href="https://arxiv.org/abs/2401.09386">Paper</a>]
                                [<a href="https://github.com/Songluchuan/Tri2plane">Project</a>]
                                [<a href="https://github.com/Songluchuan/Tri2plane">Code</a>]
                                [<a href="https://github.com/Songluchuan/Tri2plane">Demo</a>]
                            </div>
                        </div>
                        <div style="clear:both;"></div>
                </li>
                
                <li class="item_format" style="position:relative">
                    <img src="./research/pipeline_icassp.png" class="img_format">
                        <div class="title_format">
                            <b>Adaptive Super Resolution For One-Shot Talking-Head Generation</b>
                            <span class="author_format">Luchuan Song, <b style="color: #800000">Pinxin Liu</b>, Guojun Yin, Chenliang Xu.</span>
                            <span class="venue_format"><em style="color: #008B8B">ICASSP 2024</em></span>
                            <div class="link_format">
                                [<a href="https://github.com/Songluchuan/AdaSR-TalkingHead/">Paper</a>]
                                [<a href="https://github.com/Songluchuan/AdaSR-TalkingHead/">Project</a>]
                                <!-- [<a href="https://people.engr.tamu.edu/nimak/Papers/ICCP2021_denoising/index.html">Project</a>] -->
                                <!-- [<a href="https://github.com/avinashpaliwal/MaskDnGAN">Code</a>] -->
                                [<a href="https://github.com/Songluchuan/AdaSR-TalkingHead/">Code</a>]
                            </div>
                        </div>
                        <div style="clear:both;"></div>
                </li>


                <li class="item_format" style="position:relative">
                    <img src="./research/commonsense.png" class="img_format">
                        <div class="title_format">
                            <b>Contextualized Multi-Step Commonsense Reasoning through Context Extension</b>
                            <span class="author_format">Hecong Wang, Erqian Xu, <b style="color: #800000">Pinxin Liu</b>, Zijian Meng, Zhen Bai.</span>
                            <span class="venue_format"><em style="color: #008B8B">AAAI Workshop 2023</em></span>
                            <div class="link_format">
                                [<a href="https://r2hcai.github.io/AAAI-23/files/CameraReadys/47.pdf">Paper</a>]
                            </div>
                        </div>
                        <div style="clear:both;"></div>
                </li>

            </ol>
        </div>
        
        
        <div>
            <span class="category">TEACHING</span>
            <hr class="line">
            <ul class="item_content">
                <li>
                    <a href="https://www.cs.rochester.edu/~cxu22/t/249S24/"> 2024 Spring CSC 2/449: Machine Vision</a>
                    <span class="author_format">Instructor: Dr. <a href="https://www.cs.rochester.edu/~cxu22/"> Chengliang Xu </a></span>
                </li>
                <li>
                    <a href="https://www.cs.rochester.edu/~gildea/446_Fall_2023/"> 2023 FALL CSC 446: Machine Learning</a>
                    <span class="author_format">Instructor: Dr. <a href="https://www.cs.rochester.edu/u/gildea/"> Daniel Gildea </a></span>
                </li>
                <li>
                    2023 SPRING CSC 2/447: Nature Language Processing</a>
                    <span class="author_format">Instructor: Dr. <a href="https://people.engr.tamu.edu/dzsong/index.html"> Hangfeng He </a></span>
                </li>
                <li>
                    <a href="https://www.cs.rochester.edu/~gildea/2022_Fall/"> 2022 Fall CSC 2/448 Statistical Speech and Language Processing</a>
                    <span class="author_format">Instructor: Dr. <a href="https://www.cs.rochester.edu/u/gildea/"> Daniel Gildea </a></span>
                </li>
            </ul>
        </div>


        <div>
            <span class="category">Reviewing</span>
            <hr class="line">
            <ul class="item_content">
                <li>
                    <p class="text-justify">
                        CVPR 2024, 2025, EMNLP 2023, KDD 2024, AAAI 2024, ICLR 2025, 3DV 2025
                    </p>
                </li>
            </ul>
            <hr class="line">
        </div>
        

        <div>
            <span class="category">ACKNOWLEDGEMENTS</span>
            <hr class="line">
            <ul class="item_content">
                <li>
                    <p class="text-justify">
                        The website template was borrowed from <a href="http://junxnui.github.io/">Jun Xing</a>.
                    </p>
                </li>
            </ul>
            <hr class="line">
        </div>

        <div>
            <a href="https://clustrmaps.com/site/1byfb"  title="Visit tracker"><img src="//www.clustrmaps.com/map_v2.png?d=Ag-DLUyxYprkvEFDlsL7QoXf2fUFQ41ogt-7CsEBSto&cl=ffffff" /></a>
        </div>

    </div>
    

    <script src="./index/canvas-nest.js_1.0.1_canvas-nest.min.js" opacity="0.6" color="0,68,255" zindex="-1"></script><canvas id="c_n1" width="1287" height="736" style="position: fixed; top: 0px; left: 0px; z-index: -1; opacity: 0.6;"></canvas>

</body></html>
